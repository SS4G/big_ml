{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "## for printing image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/szh/workspace/fast_work/big_ml/pytorch_demo\n"
     ]
    }
   ],
   "source": [
    "cd /home/szh/workspace/fast_work/big_ml/pytorch_demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#label_dict = {2: 0, 3: 1,  4:2,  5:3,  6:4,  8:5,  9:6, 10:7, 12:8, 13:9, 16:10, 17:11, 18:12, 25:13, 31:14, 38:15, 39:16, 42:17, 22:18}\n",
    "jpg_path = \"./data/GTSRB_train_jpgs/\"\n",
    "files = [file for file in os.listdir(jpg_path) if \".jpg\" in file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread(jpg_path + '00017#00025_00014.jpg')\n",
    "cv2.resize(img, (32, 32)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_size = (32, 32)\n",
    "images = [cv2.cvtColor(cv2.resize(cv2.imread(jpg_path + file), std_size), cv2.COLOR_BGR2GRAY).reshape(1, std_size[0], std_size[1]) for file in files]\n",
    "labels = [int(file.split(\"#\")[0]) for file in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[17, 10, 9]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00017#00025_00014.jpg',\n",
       " '00010#00015_00006.jpg',\n",
       " '00009#00027_00011.jpg',\n",
       " '00005#00002_00015.jpg']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_tensors = torch.FloatTensor(images)\n",
    "label_tensors = torch.tensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_imgs.size torch.Size([16, 1, 32, 32])\n",
      "batch_labels.size torch.Size([16])\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 16\n",
    "for i in range(0, image_tensors.shape[0], BATCH_SIZE):\n",
    "    batch_imgs = image_tensors[i: i + BATCH_SIZE]\n",
    "    batch_labels = label_tensors[i: i + BATCH_SIZE]\n",
    "    print(\"batch_imgs.size\", batch_imgs.shape)\n",
    "    print(\"batch_labels.size\", batch_labels.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "## the model \n",
    "class MyLenet5Model(nn.Module): \n",
    "    def __init__(self): \n",
    "        # 在init中定义 各层对象结构\n",
    "        super(MyLenet5Model, self).__init__() \n",
    "        # 就是一般的全连接层 第一个参数是输入维度 第二个参数是输出维度\n",
    "        # 层对象应该就是一个有了部分参数的偏函数 最后的一个参数就是数据 \n",
    "        self.c1 = torch.nn.Conv2d(1, 6, (5, 5), stride=1, padding=0, bias=True, padding_mode='zeros')\n",
    "        self.s2 = torch.nn.MaxPool2d((2, 2), stride=None, padding=0)\n",
    "        self.c3 = torch.nn.Conv2d(6, 16, (5, 5), stride=1, padding=0, bias=True, padding_mode='zeros')\n",
    "        self.s4 = torch.nn.MaxPool2d((2, 2), stride=None, padding=0)\n",
    "        self.d1 = nn.Linear(400, 120) \n",
    "        #self.dropout = nn.Dropout(p=0.2) \n",
    "        self.d2 = nn.Linear(120, 84) \n",
    "        self.d3 = nn.Linear(84, 43)\n",
    "        \n",
    "    def forward(self, x): \n",
    "        # 使用init中创建的层对象 构建网络的连接关系\n",
    "        #print(\"input_shape\", x.shape)\n",
    "        x = self.c1(x)\n",
    "        x = F.relu(x) \n",
    "        x = self.s2(x)\n",
    "        x = self.c3(x)\n",
    "        x = F.relu(x) \n",
    "        x = self.s4(x)\n",
    "        x = x.flatten(start_dim=1) # 把3d(depth,x,y)的图像数据展平为一维的 这里用的就是普通神经网络不是CNN\n",
    "        x = self.d1(x)  # 全连接层1\n",
    "        x = F.relu(x)   # relu 激活函数 \n",
    "        x = self.d2(x)  # 全连接层1\n",
    "        x = F.relu(x)   # relu 激活函数 \n",
    "        logits = self.d3(x)\n",
    "        out = F.softmax(logits, dim=1)  \n",
    "        return out\n",
    "        #return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01 \n",
    "num_epochs = 5 \n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else\"cpu\") \n",
    "model = MyLenet5Model() \n",
    "model = model.to(device) # 模型放到CPU 或者GPU上\n",
    "criterion = nn.CrossEntropyLoss() # 定义损失函数\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自己写一个计算准确度的函数\n",
    "def get_accuracy(output, target, batch_size):\n",
    "    ''' Obtain accuracy for training round '''\n",
    "    corrects = (torch.max(output, 1)[1].view(target.size()).data == target.data).sum() \n",
    "    accuracy = 100.0 * corrects/batch_size \n",
    "    return accuracy.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Loss: 0.2343 | Train Accuracy: 0.32\n",
      "Epoch: 1 | Loss: 0.2343 | Train Accuracy: 0.32\n",
      "Epoch: 2 | Loss: 0.2343 | Train Accuracy: 0.32\n",
      "Epoch: 3 | Loss: 0.2343 | Train Accuracy: 0.32\n",
      "Epoch: 4 | Loss: 0.2343 | Train Accuracy: 0.32\n"
     ]
    }
   ],
   "source": [
    "## train the model \n",
    "for epoch in range(num_epochs): \n",
    "    train_running_loss = 0.0 \n",
    "    train_acc = 0.0 \n",
    "     ## commence training \n",
    "    model = model.train() \n",
    "     ## training step \n",
    "    for i in range(0, image_tensors.shape[0], BATCH_SIZE):\n",
    "        batch_imgs = image_tensors[i: i + BATCH_SIZE]\n",
    "        batch_labels = label_tensors[i: i + BATCH_SIZE]\n",
    "        batch_imgs = batch_imgs.to(device) \n",
    "        batch_labels = batch_labels.to(device)  \n",
    "        batch_predictions = model(batch_imgs)  # model object is a function\n",
    "        loss = criterion(batch_predictions, batch_labels) \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        ## update model params \n",
    "        optimizer.step()\n",
    "        train_running_loss += loss.detach().item() \n",
    "        train_acc += get_accuracy(batch_predictions, batch_labels, BATCH_SIZE) \n",
    "    model.eval()\n",
    "    print('Epoch: %d | Loss: %.4f | Train Accuracy: %.2f' %(epoch,train_running_loss / i, train_acc/i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else\"cpu\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda:0'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"cuda:0\" if torch.cuda.is_available() else\"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
