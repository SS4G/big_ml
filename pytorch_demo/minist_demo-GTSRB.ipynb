{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The usual imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "## for printing image\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1.0.post2\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else\"cpu\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "## parameter denoting the batch size \n",
    "BATCH_SIZE = 32 \n",
    "## transformations Compose 将多个transform 放在参数的list中\n",
    "transform = transforms.Compose([transforms.ToTensor()]) \n",
    "## download and load training dataset \n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform) \n",
    "# data loader 本身只是一个lodaer 记录了一些 数据的batch_size 以及是否shuffle等信息 以及关联的数据\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2) \n",
    "## download and load testing dataset \n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform) \n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.utils.data.dataloader.DataLoader"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(trainset)\n",
    "type(trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image batch dimensions: torch.Size([32, 1, 28, 28])\n",
      "Image label dimensions: torch.Size([32])\n",
      "tensor([9, 9, 5, 5, 9, 8, 6, 8, 6, 4, 7, 1, 2, 7, 0, 7, 9, 5, 9, 4, 4, 1, 8, 2,\n",
      "        9, 0, 6, 3, 6, 4, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "# train loader 实际上是一个包装好的迭代器\n",
    "# torch.Size([32, 1, 28, 28])\n",
    "for images, labels in trainloader: \n",
    "    print(\"Image batch dimensions:\", images.shape) \n",
    "    print(\"Image label dimensions:\", labels.shape) \n",
    "    print(labels)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "labels.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#label_dict = {2: 0, 3: 1,  4:2,  5:3,  6:4,  8:5,  9:6, 10:7, 12:8, 13:9, 16:10, 17:11, 18:12, 25:13, 31:14, 38:15, 39:16, 42:17, 22:18}\n",
    "jpg_path = \"./data/GTSRB_train_jpgs/\"\n",
    "files = [file for file in os.listdir(jpg_path) if \".jpg\" in file]\n",
    "std_size = (28, 28)\n",
    "images = [cv2.cvtColor(cv2.resize(cv2.imread(jpg_path + file), std_size), cv2.COLOR_BGR2GRAY).reshape(1, std_size[1], std_size[0]) for file in files]\n",
    "labels = [file.split(\"#\")[0] for file in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tain_data_loader(train_set):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 继承nn.Module 模块定义一个神经网络的前馈结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "## the model \n",
    "class MyModel(nn.Module): \n",
    "    def __init__(self): \n",
    "        # 在init中定义 各层对象结构\n",
    "        super(MyModel, self).__init__() \n",
    "        # 就是一般的全连接层 第一个参数是输入维度 第二个参数是输出维度\n",
    "        # 注意卷积层的输入为尺寸为 (N, Channel, Height, Width)\n",
    "        # \n",
    "        self.c1 = torch.nn.Conv2d(1, 6, (5, 5), stride=1, padding=0, bias=True, padding_mode='zeros')\n",
    "        self.s2 = torch.nn.MaxPool2d((2, 2))\n",
    "        self.c3 = torch.nn.Conv2d(6, 16, (5, 5), stride=1, padding=0, bias=True, padding_mode='zeros')\n",
    "        self.s4 = torch.nn.MaxPool2d((2, 2))\n",
    "        self.d1 = nn.Linear(256, 120) \n",
    "        #self.dropout = nn.Dropout(p=0.2) \n",
    "        self.d2 = nn.Linear(120, 84) \n",
    "        self.d3 = nn.Linear(84, 10)\n",
    "        \n",
    "    def forward(self, x): \n",
    "        # 使用init中创建的层对象 构建网络的连接关系\n",
    "        #print(\"input_shape\", x.shape)\n",
    "        x =  F.relu(self.s2(self.c1(x)))\n",
    "        x =  F.relu(self.s4(self.c3(x)))\n",
    "        x = x.view(-1, 256) # 把3d(depth,x,y)的图像数据展平为一维的 这里用的就是普通神经网络不是CNN\n",
    "        x = F.relu(self.d1(x))  # 全连接层1\n",
    "        x = F.relu(self.d2(x))  # 全连接层1\n",
    "        x = self.d3(x)\n",
    "        out = F.log_softmax(x, dim=1)\n",
    "        #exit()\n",
    "        return out\n",
    "        #return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 开始训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001 \n",
    "num_epochs = 5 \n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else\"cpu\") \n",
    "model = MyModel() \n",
    "model = model.to(device) # 模型放到CPU 或者GPU上\n",
    "criterion = nn.CrossEntropyLoss() # 定义损失函数\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "## utility function to compute accuracy \n",
    "# 自己写一个计算准确度的函数\n",
    "def get_accuracy(output, target, batch_size):\n",
    "    ''' Obtain accuracy for training round '''\n",
    "    corrects = (torch.max(output, 1)[1].view(target.size()).data == target.data).sum() \n",
    "    accuracy = 100.0 * corrects/batch_size \n",
    "    return accuracy.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Loss: 0.2493 | Train Accuracy: 91.62\n",
      "Epoch: 1 | Loss: 0.0774 | Train Accuracy: 97.23\n",
      "Epoch: 2 | Loss: 0.0552 | Train Accuracy: 97.91\n",
      "Epoch: 3 | Loss: 0.0431 | Train Accuracy: 98.42\n",
      "Epoch: 4 | Loss: 0.0368 | Train Accuracy: 98.58\n"
     ]
    }
   ],
   "source": [
    "## train the model \n",
    "for epoch in range(num_epochs): \n",
    "    train_running_loss = 0.0 \n",
    "    train_acc = 0.0 \n",
    "     ## commence training \n",
    "    model = model.train() \n",
    "     ## training step \n",
    "    for i, (images, labels) in enumerate(trainloader): \n",
    "        images = images.to(device) \n",
    "        labels = labels.to(device) \n",
    "         ## forward + backprop + loss \n",
    "        predictions = model(images) \n",
    "        #print(predictions, predictions.shape)\n",
    "        #print(labels, labels.shape)\n",
    "        #break\n",
    "        loss = criterion(predictions, labels) \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        ## update model params \n",
    "        optimizer.step()\n",
    "        train_running_loss += loss.detach().item() \n",
    "        train_acc += get_accuracy(predictions, labels, BATCH_SIZE) \n",
    "    model.eval()\n",
    "    print('Epoch: %d | Loss: %.4f | Train Accuracy: %.2f' %(epoch,train_running_loss / i, train_acc/i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TestAccuracy: 98.91\n"
     ]
    }
   ],
   "source": [
    "test_acc = 0.0 \n",
    "for i, (images, labels) in enumerate(testloader, 0): \n",
    "    images = images.to(device) \n",
    "    labels = labels.to(device) \n",
    "    outputs = model(images) \n",
    "    test_acc+= get_accuracy(outputs, labels, BATCH_SIZE) \n",
    "print('TestAccuracy: %.2f' % (test_acc / i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
