{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The usual imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "## for printing image\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1.0.post2\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如果GPU可用将使用GPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else\"cpu\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导入并准备数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## parameter denoting the batch size\n",
    "# 并读取图像文件\n",
    "BATCH_SIZE = 32 \n",
    "jpg_path = \"./data/GTSRB_train_jpgs/\"\n",
    "files = [file for file in os.listdir(jpg_path) if \".jpg\" in file]\n",
    "std_size = (28, 28)\n",
    "images = [cv2.cvtColor(cv2.resize(cv2.imread(jpg_path + file), std_size), cv2.COLOR_BGR2GRAY).reshape(1, std_size[1], std_size[0]) for file in files]\n",
    "labels = [int(file.split(\"#\")[0]) for file in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将读取到的图像文件转化为Tensor 但是当前的训练数据 tensor是整数类型的 \n",
    "# 不能直接用于训练需要在后续步骤中转化为float类型 \n",
    "images_tensor = torch.tensor(images)\n",
    "labels_tensor = torch.tensor(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "labels.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 编写一个生成器 用于逐个batch 将数据迭代产生 \n",
    "# 此处注意数据的类型 用来训练的图像数据要转化为 torch.FloatTensor (float32)\n",
    "# 标签要转化为 torch.LongTensor (int64)\n",
    "def train_data_loader(train_set, labels, batch_size):\n",
    "    for i in range(0, train_set.shape[0], batch_size):\n",
    "        batch_imgs = train_set[i: i + batch_size].type(torch.FloatTensor)\n",
    "        batch_labels = labels[i: i + batch_size].type(torch.LongTensor)\n",
    "        yield (batch_imgs, batch_labels)\n",
    "\n",
    "# 卷积层的输入尺寸为 (Batch_size, Channel, Height, Width) 对于灰度图像 Channel为1 RGB图像为1 \n",
    "# 对于其他卷积层产生的输入 Channel 为上一层卷积核的个数\n",
    "# 使用view函数对矩阵的形状进行变换\n",
    "# 所以上述的输入为\n",
    "# torch.Size([32, 1, 28, 28])\n",
    "def my_loader():\n",
    "    return train_data_loader(images_tensor.view(images_tensor.shape[0], 1, 28, 28), labels_tensor, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image batch dimensions: torch.Size([32, 1, 28, 28]) torch.float32\n",
      "Image label dimensions: torch.Size([32]) torch.int64\n",
      "tensor([12,  9, 25,  7,  1, 10, 23, 35,  2, 13, 28,  4, 11, 17,  2, 35, 33, 11,\n",
      "        25,  9, 12,  1, 38, 42, 25,  3,  9, 12,  7,  1, 10, 42])\n",
      "<class 'function'>\n"
     ]
    }
   ],
   "source": [
    "# 查看一下迭代的结果\n",
    "for images, labels in my_loader(): \n",
    "    print(\"Image batch dimensions:\", images.shape, images.dtype) \n",
    "    print(\"Image label dimensions:\", labels.shape, labels.dtype) \n",
    "    print(labels)\n",
    "    break\n",
    "print(type(my_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 继承nn.Module 模块定义一个神经网络的前馈结构\n",
    "- 在torch中 定义网络的前馈结构即可 \n",
    "- 需要继承nn.Module \n",
    "- 在__init__ 中定义网络的常量 以及 各个层的尺寸 \n",
    "- 定义一个层如下   \n",
    "```self.c3 = torch.nn.Conv2d(6, 16, (5, 5), stride=1, padding=0, bias=True, padding_mode='zeros')```    \n",
    "   实际上是定义了一个偏函数, 偏函数包括了卷积尺寸，核数量等信息 但是就是 没有输入数据x\n",
    "- forward中定义 网络真正的结构 使用__init__中事先定义好的偏函数 定义各个偏函数与输入和输出的关系 \n",
    "- 构建过程相当于写下一个大号的公式 forward 返回最终通过网络的输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module): \n",
    "    def __init__(self): \n",
    "        # 在init中定义 各层对象结构\n",
    "        super(MyModel, self).__init__() \n",
    "        self.class_num = 43\n",
    "        # 就是一般的全连接层 第一个参数是输入维度 第二个参数是输出维度\n",
    "        # 注意卷积层的输入为尺寸为 (N, Channel, Height, Width)\n",
    "        # \n",
    "        self.c1 = torch.nn.Conv2d(1, 6, (5, 5), stride=1, padding=0, bias=True, padding_mode='zeros')\n",
    "        self.s2 = torch.nn.MaxPool2d((2, 2))\n",
    "        self.c3 = torch.nn.Conv2d(6, 16, (5, 5), stride=1, padding=0, bias=True, padding_mode='zeros')\n",
    "        self.s4 = torch.nn.MaxPool2d((2, 2))\n",
    "        self.d1 = nn.Linear(256, 120) \n",
    "        #self.dropout = nn.Dropout(p=0.2) \n",
    "        self.d2 = nn.Linear(120, 84) \n",
    "        self.d3 = nn.Linear(84, self.class_num)\n",
    "        \n",
    "    def forward(self, x): \n",
    "        # 使用init中创建的层对象 构建网络的连接关系\n",
    "        #print(\"input_shape\", x.shape)\n",
    "        x =  F.relu(self.s2(self.c1(x)))\n",
    "        x =  F.relu(self.s4(self.c3(x)))\n",
    "        x = x.view(-1, 256) # 把3d(depth,x,y)的图像数据展平为一维的 这里用的就是普通神经网络不是CNN\n",
    "        x = F.relu(self.d1(x))  # 全连接层1\n",
    "        x = F.relu(self.d2(x))  # 全连接层1\n",
    "        x = self.d3(x)\n",
    "        out = F.log_softmax(x, dim=1)\n",
    "        #exit()\n",
    "        return out\n",
    "        #return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 开始训练模型\n",
    "- 训练模型就是通过比对模型的输出和真实的输出之间的差距 然后使用梯度下降法调整模型参数 减小这种差距\n",
    "- 首先除了上面一步定义好的模型之外 还要定义损失函数 也就是衡量模型输出和真实值之间差距的函数 \n",
    "  损失函数的输出就是 loss 我们的目标就是优化loss\n",
    "- 优化器optimizer 可以看做是一个包含了模型参数的容器 在backward之后 可以操作 更新模型中的参数 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001 \n",
    "num_epochs = 5 \n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else\"cpu\") \n",
    "model = MyModel() \n",
    "model = model.to(device) # 模型放到CPU 或者GPU上\n",
    "criterion = nn.CrossEntropyLoss() # 定义损失函数\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 自己写一个计算准确度的函数\n",
    "- 计算当前的batch中的准确度 torch.max(output, 1) 中的第二个参数表示在第1个维度(维度编号从0开始)中求最大值 \n",
    "- 该函数除了返回对应的最大值还会返回对应维度中的最大值所在的index 很方便 下面是返回示例   \n",
    "\n",
    "```\n",
    "torch.return_types.max(\n",
    "values=tensor([1.3117, 2.0132, 1.4627, 1.4121, 1.5152, 1.5220, 1.8655, 2.3365, 1.8300,\n",
    "        1.2343], dtype=torch.float64),\n",
    "indices=tensor([0, 5, 9, 7, 6, 0, 4, 6, 7, 8]))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(output, target, batch_size):\n",
    "    ''' Obtain accuracy for training round '''\n",
    "    corrects = (torch.max(output, 1)[1].view(target.size()).data == target.data).sum() \n",
    "    accuracy = 100.0 * corrects/batch_size \n",
    "    return accuracy.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 定义好迭代的轮数 在每一轮训练中要吧 \n",
    "- 当前优化器中的梯度清零 CNN中 不能累加梯度  RNN中可能有需要 \n",
    "  [zero_grad的解释](https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
    "- 每轮训练遵循的流程都是 输入数据->神经网络模型->计算loss->backward()->optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Loss: 0.8793 | Train Accuracy: 77.51\n",
      "Epoch: 1 | Loss: 0.2446 | Train Accuracy: 93.33\n",
      "Epoch: 2 | Loss: 0.1621 | Train Accuracy: 95.43\n",
      "Epoch: 3 | Loss: 0.1355 | Train Accuracy: 95.98\n",
      "Epoch: 4 | Loss: 0.1154 | Train Accuracy: 96.51\n"
     ]
    }
   ],
   "source": [
    "## train the model \n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs): \n",
    "    train_running_loss = 0.0 \n",
    "    train_acc = 0.0 \n",
    "     ## commence training \n",
    "    model = model.train() \n",
    "     ## training step \n",
    "    #for i, (images, labels) in enumerate(train_data_loader()): \n",
    "    for i, (images, labels) in enumerate(my_loader()):\n",
    "        images = images.to(device) \n",
    "        labels = labels.to(device) \n",
    "         ## forward + backprop + loss \n",
    "        predictions = model(images) \n",
    "        #print(predictions, predictions.shape)\n",
    "        #print(labels, labels.shape)\n",
    "        #break\n",
    "        loss = criterion(predictions, labels) \n",
    "        optimizer.zero_grad() # 梯度清零\n",
    "        loss.backward()\n",
    "        ## update model params \n",
    "        optimizer.step() # 更新模型参数 \n",
    "        train_running_loss += loss.detach().item()  # 累加loss时记得断开求导 不然会变成求累加loss的导数\n",
    "        train_acc += get_accuracy(predictions, labels, BATCH_SIZE) \n",
    "    model.eval()\n",
    "    print('Epoch: %d | Loss: %.4f | Train Accuracy: %.2f' %(epoch,train_running_loss / i, train_acc/i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 输入测试数据进行预测\n",
    "- 可以看出就是直接把数据灌入到model中就可以了 \n",
    "- 为了方便下面的例子只预测了一个batch中的准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 batch test_acc 100\n"
     ]
    }
   ],
   "source": [
    "test_acc = 0.0 \n",
    "labels = None\n",
    "outputs = None\n",
    "for i, (images, labels) in enumerate(my_loader()): \n",
    "    images = images.to(device) \n",
    "    labels = labels.to(device) \n",
    "    outputs = model(images)\n",
    "    break\n",
    "print(\"1 batch test_acc\", get_accuracy(outputs, labels, BATCH_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
